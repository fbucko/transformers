{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3252e87a",
   "metadata": {},
   "source": [
    "Author: Filip Bucko  \n",
    "Email: xbucko05@vutbr.cz  \n",
    "Institution: Brno University of Technology - Faculty of Information Technology  \n",
    "Date: 18.5.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60edca49",
   "metadata": {},
   "source": [
    "# Flatten Domainâ€“IP JSON to a Tidy DataFrame\n",
    "\n",
    "This notebook processes a large JSON-Lines export of domain-IP mappings, exploding the `ip_data` list to yield one row per IP, flattening nested structures with `pandas.json_normalize`, and preparing transformer-ready input strings. The final balanced dataset is written to CSV for downstream modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78355d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4070fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def stream_json(path: Path):\n",
    "    \"\"\"\n",
    "    Memory-efficient JSONL reader: yields one JSON object per non-empty line.\n",
    "    \"\"\"\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                yield json.loads(line)\n",
    "\n",
    "def geo_tokens_from_ip_data(ip_data):\n",
    "    \"\"\"\n",
    "    Convert geo sub-objects in ip_data into tokens summarizing\n",
    "    counts and unique country/region/city/timezone values.\n",
    "    \"\"\"\n",
    "    if not ip_data:\n",
    "        return [\n",
    "            \"ip_count: 0\",\n",
    "            \"countries: NA\",\n",
    "            \"regions: NA\",\n",
    "            \"cities: NA\",\n",
    "            \"timezones: NA\"\n",
    "        ]\n",
    "\n",
    "    ip_count = len(ip_data)\n",
    "    countries, regions, cities, timezones = set(), set(), set(), set()\n",
    "\n",
    "    for rec in ip_data:\n",
    "        if isinstance(rec, dict):\n",
    "            geo = rec.get(\"geo\") or {}\n",
    "            countries.add(geo.get(\"country\") or geo.get(\"country_code\") or \"NA\")\n",
    "            regions.add(geo.get(\"region\") or \"NA\")\n",
    "            cities.add(geo.get(\"city\") or \"NA\")\n",
    "            timezones.add(geo.get(\"timezone\") or \"NA\")\n",
    "\n",
    "    def uniq(vals):\n",
    "        vals.discard(\"NA\")\n",
    "        return \", \".join(sorted(vals)) if vals else \"NA\"\n",
    "\n",
    "    return [\n",
    "        f\"ip_count: {ip_count}\",\n",
    "        f\"countries: {uniq(countries)}\",\n",
    "        f\"regions: {uniq(regions)}\",\n",
    "        f\"cities: {uniq(cities)}\",\n",
    "        f\"timezones: {uniq(timezones)}\"\n",
    "    ]\n",
    "\n",
    "def prepare_geo_input_string(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Build a single input string for transformer models from domain_name and ip_data.\n",
    "    \"\"\"\n",
    "    CLS, SEP = \"[CLS]\", \"[SEP]\"\n",
    "    domain = (row.get(\"domain_name\") or \"NA\").lower().lstrip(\"www.\")\n",
    "    tokens = [f\"domain: {domain}\"] + geo_tokens_from_ip_data(row.get(\"ip_data\"))\n",
    "    return f\"{CLS} \" + f\" {SEP} \".join(tokens) + f\" {SEP}\"\n",
    "\n",
    "def build_dataset(json_path: Path, label: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a JSONL file, build input strings, assign label,\n",
    "    and return only 'input_string' and 'label' columns.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(stream_json(json_path))\n",
    "    df[\"input_string\"] = df.apply(prepare_geo_input_string, axis=1)\n",
    "    df[\"label\"] = label\n",
    "    return df[[\"input_string\", \"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15130b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /home/fetagpu/Work/01-transofmers/datasets/malware/geo_malware_preprocessed_2.csv with 201618 rows (100809 phishing + 100809 benign)\n"
     ]
    }
   ],
   "source": [
    "# Load, balance, and save\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "\n",
    "# malicious_path  = project_root / \"datasets\" / \"phishing\" / \"phishing_strict_ip_2024.json\"\n",
    "malicious_path  = project_root / \"datasets\" / \"malware\" / \"malware_strict_ip_2024.json\"\n",
    "benign_path = project_root / \"datasets\" / \"benign\"   / \"benign_2312_anonymized_ip_2024.json\"\n",
    "\n",
    "# df_malware  = build_dataset(malware_path,  label=1)\n",
    "df_malicious  = build_dataset(malicious_path,  label=1)\n",
    "df_benign = build_dataset(benign_path, label=0)\n",
    "\n",
    "minority_size = min(len(df_malicious), len(df_benign))\n",
    "malicious_bal  = df_malicious.sample(n=minority_size, random_state=42)\n",
    "benign_bal = df_benign.sample(n=minority_size, random_state=42)\n",
    "\n",
    "balanced = pd.concat([malicious_bal, benign_bal], ignore_index=True)\n",
    "balanced = balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# out_path = project_root / \"datasets\" / \"phishing\" / \"geo_phishing_preprocessed.csv\"\n",
    "out_path = project_root / \"datasets\" / \"malware\" / \"geo_malware_preprocessed_2.csv\"\n",
    "balanced.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Wrote {out_path.resolve()} with {balanced.shape[0]} rows \"\n",
    "      f\"({minority_size} phishing + {minority_size} benign)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
